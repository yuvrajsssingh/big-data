(1).What is HIVE
Hive is a data warehouse system which is used to analyze structured data. It is built on the top of Hadoop. It was developed by Facebook.
Hive provides the functionality of reading, writing, and managing large datasets residing in distributed storage. It runs SQL like queries called HQL (Hive query language) which gets internally converted to MapReduce jobs.
Using Hive, we can skip the requirement of the traditional approach of writing complex MapReduce programs. Hive supports Data Definition Language (DDL), Data Manipulation Language (DML), and User Defined Functions (UDF  ).

(2).Features of Hive
Hive is fast and scalable.
It provides SQL-like queries (i.e., HQL) that are implicitly transformed to MapReduce or Spark jobs.
It is capable of analyzing large datasets stored in HDFS.
It allows different storage types such as plain text, RCFile, and HBase.
It uses indexing to accelerate queries.
It can operate on compressed data stored in the Hadoop ecosystem.
It supports user-defined functions (UDFs) where user can provide its functionality.

(3).Limitations of Hive
Hive is not capable of handling real-time data.
It is not designed for online transaction processing.
Hive queries contain high latency.

(4).Hive - Create Database
In Hive, the database is considered as a catalog or namespace of tables. So, we can maintain multiple tables within a database where a unique name is assigned to each table. Hive also provides a default database with a name default.
Initially, we check the default database provided by Hive. So, to check the list of existing databases, follow the below command: -  
hive> show databases;  

(5).Drop Database
Drop Database is a statement that drops all the tables and deletes the database. Its syntax is as follows:
The following queries are used to drop a database. Let us assume that the database name is userdb.
hive> DROP DATABASE IF EXISTS userdb;

(6).Create Table
Create Table is a statement used to create a table in Hive. The syntax and example are as follows:
The following query creates a table named employee using the above data.
hive> CREATE TABLE IF NOT EXISTS employee ( eid int, name String,
salary String, destination String)
COMMENT ‘Employee details’
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ‘\t’
LINES TERMINATED BY ‘\n’
STORED AS TEXTFILE;

(7).Alter Table
It is used to alter a table in Hive.
The statement takes any of the following syntaxes based on what attributes we wish to modify in a table.
ALTER TABLE name RENAME TO new_name
ALTER TABLE name ADD COLUMNS (col_spec[, col_spec ...])
ALTER TABLE name DROP [COLUMN] column_name
ALTER TABLE name CHANGE column_name new_name new_type
ALTER TABLE name REPLACE COLUMNS (col_spec[, col_spec ...])

(8).Drop Table
The syntax is as follows:
The following query drops a table named employee:
hive> DROP TABLE IF EXISTS employee;

(9).Hive organizes tables into partitions. 
It is a way of dividing a table into related parts based on the values of partitioned columns such as date, city, and department.
Using partition, it is easy to query a portion of the data.
As we know that Hadoop is used to handle the huge amount of data, it is always required to use the best approach to deal with it. The partitioning in Hive is the best example of it.
The partitioning in Hive can be executed in two ways -
Static partitioning
Dynamic partitioning

Static Partitioning
In static or manual partitioning, it is required to pass the values of partitioned columns manually while loading the data into the table. Hence, 
the data file doesn't contain the partitioned columns.

Create the table and provide the partitioned columns by using the following command: -
hive> create table student (id int, name string, age int,  institute string)   
partitioned by (course string)  
row format delimited  
fields terminated by ',';  

Dynamic Partitioning
In dynamic partitioning, the values of partitioned columns exist within the table. So, it is not required to pass the values of partitioned columns manually.
Enable the dynamic partition by using the following commands: -
hive> set hive.exec.dynamic.partition=true;    
hive> set hive.exec.dynamic.partition.mode=nonstrict;  

Create a dummy table to store the data.
hive> create table stud_demo(id int, name string, age int, institute string, course string)   
row format delimited  
fields terminated by ',';  

Now, load the data into the table.
hive> load data local inpath '/home/codegyani/hive/student_details' into table stud_demo;  

Create a partition table by using the following command: -
hive> create table student_part (id int, name string, age int, institute string)   
partitioned by (course string)  
row format delimited  
fields terminated by ',';  

Now, insert the data of dummy table into the partition table.
hive> insert into student_part  
partition(course)  
select id, name, age, institute, course  
from stud_demo;  

(10).Bucketing in Hive
The bucketing in Hive is a data organizing technique.
It is similar to partitioning in Hive with an added functionality that it divides large datasets into more manageable parts known as buckets. 
So, we can use bucketing in Hive when the implementation of partitioning becomes difficult.
However, we can also divide partitions further in buckets.
Create a dummy table to store the data.
hive> create table emp_demo (Id int, Name string , Salary float)    
row format delimited    
fields terminated by ',' ;   

Now, load the data into the table.
hive> load data local inpath '/home/codegyani/hive/emp_details' into table emp_demo;

Enable the bucketing by using the following command: -
hive> set hive.enforce.bucketing = true;  

Create a bucketing table by using the following command: -
hive> create table emp_bucket(Id int, Name string , Salary float)    
clustered by (Id) into 3 buckets  
row format delimited    
fields terminated by ',' ;    

Now, insert the data of dummy table into the bucketed table.
hive> insert overwrite table emp_bucket select * from emp_demo;    

(11).Hive - View and Indexes
This chapter describes how to create and manage views.
Views are generated based on user requirements.
You can save any result set data as a view. 
The usage of view in Hive is same as that of the view in SQL.
It is a standard RDBMS concept. We can execute all DML operations on a view.

Creating a View
You can create a view at the time of executing a SELECT statement. The syntax is as follows:

CREATE VIEW [IF NOT EXISTS] view_name [(column_name [COMMENT column_comment], ...) ]
[COMMENT table_comment]
AS SELECT ...

Example
Let us take an example for view. Assume employee table as given below,
with the fields Id, Name, Salary, Designation, and Dept.
Generate a query to retrieve the employee details who earn a salary of more than Rs 30000. We store the result in a view named emp_30000.

The following query retrieves the employee details using the above scenario:

hive> CREATE VIEW emp_30000 AS
SELECT * FROM employee
WHERE salary>30000;

Creating an Index
An Index is nothing but a pointer on a particular column of a table.
Creating an index means creating a pointer on a particular column of a table. Its syntax is as follows:
CREATE INDEX index_name
ON TABLE base_table_name (col_name, ...)
AS 'index.handler.class.name'
[WITH DEFERRED REBUILD]
[IDXPROPERTIES (property_name=property_value, ...)]
[IN TABLE index_table_name]
[PARTITIONED BY (col_name, ...)]
[
   [ ROW FORMAT ...] STORED AS ...
   | STORED BY ...
]
[LOCATION hdfs_path]
[TBLPROPERTIES (...)]

Example
Let us take an example for index. Use the same employee table that we have used earlier with the fields Id, Name, Salary, Designation, and Dept. 
Create an index named index_salary on the salary column of the employee table.

The following query creates an index:

hive> CREATE INDEX inedx_salary ON TABLE employee(salary)
AS 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler';

(12).HiveQL - ORDER BY and SORT BY Clause
HiveQL - ORDER BY Clause
In HiveQL, ORDER BY clause performs a complete ordering of the query result set. Hence, the complete data is passed through a single reducer.
This may take much time in the execution of large datasets. However, we can use LIMIT to minimize the sorting time.
HiveQL - SORT BY Clause
The HiveQL SORT BY clause is an alternative of ORDER BY clause. It orders the data within each reducer. Hence, it performs the local ordering, where each reducer's output is sorted separately.
It may also give a partially ordered result.



